{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten,Conv2D,MaxPooling2D,BatchNormalization, Dropout    # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator                          # type: ignore\n",
    "from tensorflow.keras.models import Sequential                                               # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "source_folder_parent = r\"D:\\VSC Workspace\\breast_cancimg\\jpeg\"\n",
    "\n",
    "dicom_info = pd.read_csv(r\"D:\\VSC Workspace\\breast_cancimg\\csv\\dicom_info.csv\")\n",
    "mass_case_desc_test_set = pd.read_csv(r\"D:\\VSC Workspace\\breast_cancimg\\csv\\mass_case_description_test_set.csv\")\n",
    "mass_case_desc_train_set = pd.read_csv(r\"D:\\VSC Workspace\\breast_cancimg\\csv\\mass_case_description_train_set.csv\")\n",
    "meta = pd.read_csv(r\"D:\\VSC Workspace\\breast_cancimg\\csv\\meta.csv\")\n",
    "calc_case_desc_test_set = pd.read_csv(r\"D:\\VSC Workspace\\breast_cancimg\\csv\\calc_case_description_test_set.csv\")\n",
    "calc_case_desc_train_set = pd.read_csv(r\"D:\\VSC Workspace\\breast_cancimg\\csv\\calc_case_description_train_set.csv\")\n",
    "\n",
    "image = mass_case_desc_test_set['image'][0][7:-15]\n",
    "array = literal_eval(image)\n",
    "\n",
    "#img = cv2.imread(image)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_paths(folder):\n",
    "\n",
    "    image_paths = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "\n",
    "        image_paths.append(filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def load_images(folder, dimension):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "\n",
    "        if img is not None:\n",
    "\n",
    "            #greyscaled_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            resized_img = cv2.resize(img, (dimension, dimension))\n",
    "            images.append(resized_img)\n",
    "\n",
    "    return images\n",
    "\n",
    "def single_image_formatting(directory, dimension):\n",
    "\n",
    "    images = []\n",
    "    \n",
    "    img = cv2.imread(directory)\n",
    "    #greyscaled_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    resized_img = cv2.resize(img, (dimension, dimension))\n",
    "    \n",
    "    images.append(resized_img)\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    images = images / 255.0\n",
    "    \n",
    "    return images\n",
    "\n",
    "def final_prediction(predicted_value):\n",
    "\n",
    "    output_statement = \"\"\n",
    "    \n",
    "    val = np.round(predicted_value)\n",
    "\n",
    "    if (val == 0):\n",
    "\n",
    "        output_statement = \"happy\"\n",
    "\n",
    "    else:\n",
    "\n",
    "        output_statement = \"sad\"\n",
    "\n",
    "    return output_statement\n",
    "\n",
    "def copy_tabled_images_to_path(tableset, source_folder_parent, train_or_test, image_type):\n",
    "\n",
    "    #source_folder_parent is stand-in for folder location of 'jpeg'\n",
    "\n",
    "    #image_type refers to one of three image types among images in the 'jpeg' folder: image, cropped, and ROI_mask\n",
    "\n",
    "    image_csv_string = \"\"\n",
    "\n",
    "    if (image_type == \"image\"):\n",
    "    \n",
    "        image_csv_string = \"image file path\"\n",
    "\n",
    "    elif (image_type == \"cropped\"):\n",
    "    \n",
    "        image_csv_string = \"cropped image file path\"\n",
    "\n",
    "    else:\n",
    "    \n",
    "        image_csv_string = \"ROI mask file path\"\n",
    "\n",
    "    \n",
    "    for case in range(len(tableset)):\n",
    "\n",
    "        #patient_id = tableset['patient_id'][case]\n",
    "        path_segments = tableset[image_csv_string][case]\n",
    "        pathology = tableset['pathology'][case]\n",
    "\n",
    "        first_index = path_segments.find(\"/\")\n",
    "        second_index = path_segments.find(\"/\", first_index + 1)\n",
    "        third_index = path_segments.find(\"/\", second_index + 1)\n",
    "\n",
    "        direct_folder_path = path_segments[second_index + 1:third_index]\n",
    "        \n",
    "        source_folder = source_folder_parent + \"\\\\\" + direct_folder_path\n",
    "\n",
    "        print(source_folder) \n",
    "\n",
    "        if ((os.path.exists(source_folder)) == False):\n",
    "\n",
    "            print(direct_folder_path + \" does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        source_dir = os.listdir(source_folder)\n",
    "\n",
    "        if ((image_type != \"image\") and (image_type != \"cropped\")):\n",
    "\n",
    "            for image in source_dir:\n",
    "\n",
    "                if (image[0] == \"2\"):\n",
    "\n",
    "                    image_path = source_folder + \"\\\\\" + image\n",
    "                    print(image_path)\n",
    "                    shutil.copy(image_path, \"breast_cancer_CNN\" + \"\\\\\" + train_or_test + \"\\\\\" + image_type + \"_files\" + \"\\\\\" + pathology + \"\\\\\" + image)\n",
    "\n",
    "        else:\n",
    "\n",
    "            for image in source_dir:\n",
    "\n",
    "                if (image[0] == \"1\"):\n",
    "\n",
    "                    image_path = source_folder + \"\\\\\" + image\n",
    "                    print(image_path)\n",
    "\n",
    "                    shutil.copy(image_path, \"breast_cancer_CNN\" + \"\\\\\" + train_or_test + \"\\\\\" + image_type + \"_files\" + \"\\\\\" + pathology + \"\\\\\" + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(train_df, test_df, classes_num, end_activation, DIMENSION = 300):\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        rotation_range = 40\n",
    "\n",
    "    )\n",
    "\n",
    "    train_dataset = datagen.flow_from_directory(train_path, class_mode = \"binary\")\n",
    "    test_dataset = datagen.flow_from_directory(test_path, class_mode = \"binary\")\n",
    "\n",
    "    y_train = train_dataset.classes\n",
    "    y_test = test_dataset.classes\n",
    "\n",
    "    X_train = train_df['cropped_image']\n",
    "    X_train /= 255.0\n",
    "\n",
    "\n",
    "    X_test = test_df['cropped_image']\n",
    "    X_test /= 255.0\n",
    "\n",
    "    y_train = train_df['pathology']\n",
    "    y_test = test_df['pathology']\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),activation=\"relu\",input_shape=(DIMENSION, DIMENSION, 3)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "\n",
    "    model.add(Dense(8, activation = \"relu\"))\n",
    "    \n",
    "    model.add(Dense(classes_num, activation = end_activation))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1,patience=5)\n",
    "\n",
    "    history=model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=30, callbacks = [early_stop], shuffle=True)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Y_pred: \", y_pred)\n",
    "\n",
    "    y_pred_r = np.argmax(y_pred, axis = 1) \n",
    "\n",
    "    print(\"Y_pred_r: \", y_pred_r)\n",
    "\n",
    "    #output_list = list(zip(y_pred_r, y_test))\n",
    "    #for x in output_list:\n",
    "\n",
    "    #    print(x)\n",
    "\n",
    "    acc_score = accuracy_score(y_pred_r, y_test)\n",
    "    print(\"Accuracy Score: \", acc_score)\n",
    "\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_pred_r, y_test))\n",
    "\n",
    "    plt.plot(history.history['accuracy'], label = 'accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc = 'lower right')\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "    print(\"Test Accuracy == \", test_acc)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [[[137 137 137]\\n  [135 135 135]\\n  [133 133 1...\n",
      "1       [[[152 152 152]\\n  [156 156 156]\\n  [158 158 1...\n",
      "2       [[[  0   0   0]\\n  [  0   0   0]\\n  [  0   0  ...\n",
      "3       [[[  7   7   7]\\n  [ 13  13  13]\\n  [ 17  17  ...\n",
      "4       [[[161 161 161]\\n  [159 159 159]\\n  [156 156 1...\n",
      "                              ...                        \n",
      "1541    [[[145 145 145]\\n  [152 152 152]\\n  [154 154 1...\n",
      "1542    [[[129 129 129]\\n  [127 127 127]\\n  [133 133 1...\n",
      "1543    [[[165 165 165]\\n  [169 169 169]\\n  [164 164 1...\n",
      "1544    [[[ 10  10  10]\\n  [200 200 200]\\n  [192 192 1...\n",
      "1545    [[[203 203 203]\\n  [196 196 196]\\n  [186 186 1...\n",
      "Name: cropped_image, Length: 1546, dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_case_desc_train_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_case_desc_test_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(train_df, test_df, classes_num, end_activation, DIMENSION)\u001b[0m\n\u001b[0;32m     19\u001b[0m X_train \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcropped_image\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\n\u001b[0;32m     25\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcropped_image\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m X_test \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:12734\u001b[0m, in \u001b[0;36mNDFrame.__itruediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m  12731\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m  12732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__itruediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m  12733\u001b[0m     \u001b[38;5;66;03m# error: Unsupported left operand type for / (\"Type[NDFrame]\")\u001b[39;00m\n\u001b[1;32m> 12734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inplace_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__truediv__\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[operator]\u001b[39;49;00m\n\u001b[0;32m  12736\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:12689\u001b[0m, in \u001b[0;36mNDFrame._inplace_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m  12685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetrefcount(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m REF_COUNT \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m  12686\u001b[0m         \u001b[38;5;66;03m# we are probably in an inplace setitem context (e.g. df['a'] += 1)\u001b[39;00m\n\u001b[0;32m  12687\u001b[0m         warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m> 12689\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  12691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m  12692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m  12693\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_indexed_same(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12699\u001b[0m     \u001b[38;5;66;03m# Item \"ArrayManager\" of \"Union[ArrayManager, SingleArrayManager,\u001b[39;00m\n\u001b[0;32m  12700\u001b[0m     \u001b[38;5;66;03m# BlockManager, SingleBlockManager]\" has no attribute \"setitem_inplace\"\u001b[39;00m\n\u001b[0;32m  12701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39msetitem_inplace(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m  12702\u001b[0m         \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), result\u001b[38;5;241m.\u001b[39m_values, warn\u001b[38;5;241m=\u001b[39mwarn\n\u001b[0;32m  12703\u001b[0m     )\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:227\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32md:\\VSC Workspace\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:182\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    179\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 182\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m np\u001b[38;5;241m.\u001b[39mputmask(result, \u001b[38;5;241m~\u001b[39mmask, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m    185\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "train_network(calc_case_desc_train_set, calc_case_desc_test_set, 3, \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSION = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This cell is used to run the model with two categories from image_files: benign and malignant. This is achieved by merging contents of 'benign_without_callback' into the 'benign' folder.\n",
    "\n",
    "train_path2 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\train\\image_files\"\n",
    "test_path2 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\test\\image_files\"\n",
    "\n",
    "benign_train_path2 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\train\\image_files\\BENIGN\"\n",
    "malignant_train_path2 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\train\\image_files\\MALIGNANT\"\n",
    "\n",
    "benign_test_path2 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\test\\image_files\\BENIGN\"\n",
    "malignant_test_path2 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\test\\image_files\\MALIGNANT\"\n",
    "\n",
    "benign_train2 = load_images(benign_train_path2, DIMENSION)\n",
    "malignant_train2 = load_images(malignant_train_path2, DIMENSION)\n",
    "\n",
    "benign_test2 = load_images(benign_test_path2, DIMENSION)\n",
    "malignant_test2 = load_images(malignant_test_path2, DIMENSION)\n",
    "\n",
    "\n",
    "X_train2 = benign_train2 + malignant_train2\n",
    "X_test2 = benign_test2 + malignant_test2 \n",
    "\n",
    "X_train2 = np.array(X_train2)\n",
    "X_train2 = X_train2 / 255.0\n",
    "\n",
    "X_test2 = np.array(X_test2)\n",
    "X_test2 = X_test2 / 255.0\n",
    "\n",
    "\n",
    "#This cell is used to run the model with all three categories from image_files: benign, bwc, and malignant\n",
    "\n",
    "train_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\image_files\"\n",
    "test_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\image_files\"\n",
    "\n",
    "benign_train_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\image_files\\BENIGN\"\n",
    "benign_without_callback_train_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\image_files\\BENIGN_WITHOUT_CALLBACK\"\n",
    "malignant_train_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\image_files\\MALIGNANT\"\n",
    "\n",
    "benign_test_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\image_files\\BENIGN\"\n",
    "benign_without_callback_test_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\image_files\\BENIGN_WITHOUT_CALLBACK\"\n",
    "malignant_test_path3 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\image_files\\MALIGNANT\"\n",
    "\n",
    "benign_train3 = load_images(benign_train_path3, DIMENSION)\n",
    "benign_without_callback_train3 = load_images(benign_without_callback_train_path3, DIMENSION)\n",
    "malignant_train3 = load_images(malignant_train_path3, DIMENSION)\n",
    "\n",
    "benign_test3 = load_images(benign_test_path3, DIMENSION)\n",
    "benign_without_callback_test3 = load_images(benign_without_callback_test_path3, DIMENSION)\n",
    "malignant_test3 = load_images(malignant_test_path3, DIMENSION)\n",
    "\n",
    "\n",
    "X_train3 = benign_train3 + malignant_train3 + benign_without_callback_train3\n",
    "X_test3 = benign_test3 + malignant_test3 + benign_without_callback_test3\n",
    "\n",
    "X_train3 = np.array(X_train3)\n",
    "X_train3 = X_train3 / 255.0\n",
    "\n",
    "X_test3 = np.array(X_test3)\n",
    "X_test3 = X_test3 / 255.0\n",
    "\n",
    "\n",
    "#This cell is used to run the model with all three categories from cropped_files: benign, bwc, and malignant\n",
    "\n",
    "train_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\cropped_files\"\n",
    "test_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\cropped_files\"\n",
    "\n",
    "benign_train_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\cropped_files\\BENIGN\"\n",
    "benign_without_callback_train_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\cropped_files\\BENIGN_WITHOUT_CALLBACK\"\n",
    "malignant_train_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\train\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_test_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\cropped_files\\BENIGN\"\n",
    "benign_without_callback_test_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\cropped_files\\BENIGN_WITHOUT_CALLBACK\"\n",
    "malignant_test_path4 = r\"D:\\VSC Workspace\\breast_cancer_CNN\\test\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_train4 = load_images(benign_train_path4, DIMENSION)\n",
    "benign_without_callback_train4 = load_images(benign_without_callback_train_path4, DIMENSION)\n",
    "malignant_train4 = load_images(malignant_train_path4, DIMENSION)\n",
    "\n",
    "benign_test4 = load_images(benign_test_path4, DIMENSION)\n",
    "benign_without_callback_test4 = load_images(benign_without_callback_test_path4, DIMENSION)\n",
    "malignant_test4 = load_images(malignant_test_path4, DIMENSION)\n",
    "\n",
    "\n",
    "X_train4 = benign_train4 + malignant_train4 + benign_without_callback_train4\n",
    "X_test4 = benign_test4 + malignant_test4 + benign_without_callback_test4\n",
    "\n",
    "X_train4 = np.array(X_train4)\n",
    "X_train4 = X_train4 / 255.0\n",
    "\n",
    "X_test4 = np.array(X_test4)\n",
    "X_test4 = X_test4 / 255.0\n",
    "\n",
    "\n",
    "#This cell is used to run the model with two categories from cropped_files: benign and malignant. This is achieved by merging contents of 'benign_without_callback' into the 'benign' folder.\n",
    "\n",
    "train_path5 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\train\\cropped_files\"\n",
    "test_path5 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\test\\cropped_files\"\n",
    "\n",
    "benign_train_path5 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\train\\cropped_files\\BENIGN\"\n",
    "malignant_train_path5 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\train\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_test_path5 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\test\\cropped_files\\BENIGN\"\n",
    "malignant_test_path5 = r\"D:\\VSC Workspace\\breast_cancimg\\two_cat_images\\test\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_train5 = load_images(benign_train_path5, DIMENSION)\n",
    "malignant_train5 = load_images(malignant_train_path5, DIMENSION)\n",
    "\n",
    "benign_test5 = load_images(benign_test_path5, DIMENSION)\n",
    "malignant_test5 = load_images(malignant_test_path5, DIMENSION)\n",
    "\n",
    "\n",
    "X_train5 = benign_train5 + malignant_train5\n",
    "X_test5 = benign_test5 + malignant_test5 \n",
    "\n",
    "X_train5 = np.array(X_train5)\n",
    "X_train5 = X_train5 / 255.0\n",
    "\n",
    "X_test5 = np.array(X_test5)\n",
    "X_test5 = X_test5 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is used to run the model with all three categories from cropped_files from the combined_dataset: benign, bwc, and malignant\n",
    "\n",
    "train_path6 = r\"D:\\VSC Workspace\\combined_dataset\\train\\cropped_files\"\n",
    "test_path6 = r\"D:\\VSC Workspace\\combined_dataset\\test\\cropped_files\"\n",
    "\n",
    "benign_train_path6 = r\"D:\\VSC Workspace\\combined_dataset\\train\\cropped_files\\BENIGN\"\n",
    "benign_without_callback_train_path6 = r\"D:\\VSC Workspace\\combined_dataset\\train\\cropped_files\\BENIGN_WITHOUT_CALLBACK\"\n",
    "malignant_train_path6 = r\"D:\\VSC Workspace\\combined_dataset\\train\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_test_path6 = r\"D:\\VSC Workspace\\combined_dataset\\test\\cropped_files\\BENIGN\"\n",
    "benign_without_callback_test_path6 = r\"D:\\VSC Workspace\\combined_dataset\\test\\cropped_files\\BENIGN_WITHOUT_CALLBACK\"\n",
    "malignant_test_path6 = r\"D:\\VSC Workspace\\combined_dataset\\test\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_train6 = load_images(benign_train_path6, DIMENSION)\n",
    "benign_without_callback_train6 = load_images(benign_without_callback_train_path6, DIMENSION)\n",
    "malignant_train6 = load_images(malignant_train_path6, DIMENSION)\n",
    "\n",
    "benign_test6 = load_images(benign_test_path6, DIMENSION)\n",
    "benign_without_callback_test6 = load_images(benign_without_callback_test_path6, DIMENSION)\n",
    "malignant_test6 = load_images(malignant_test_path6, DIMENSION)\n",
    "\n",
    "\n",
    "X_train6 = benign_train6 + malignant_train6 + benign_without_callback_train6\n",
    "X_test6 = benign_test6 + malignant_test6 + benign_without_callback_test6\n",
    "\n",
    "X_train6 = np.array(X_train6)\n",
    "X_train6 = X_train6 / 255.0\n",
    "\n",
    "X_test6 = np.array(X_test6)\n",
    "X_test6 = X_test6 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is used to run the model with two categories from cropped_files in the combined_dataset: benign and malignant. This is achieved by merging contents of 'benign_without_callback' into the 'benign' folder.\n",
    "\n",
    "train_path7 = r\"D:\\VSC Workspace\\breast_cancimg\\combined_two_cat_images\\train\\cropped_files\"\n",
    "test_path7 = r\"D:\\VSC Workspace\\breast_cancimg\\combined_two_cat_images\\test\\cropped_files\"\n",
    "\n",
    "benign_train_path7 = r\"D:\\VSC Workspace\\breast_cancimg\\combined_two_cat_images\\train\\cropped_files\\BENIGN\"\n",
    "malignant_train_path7 = r\"D:\\VSC Workspace\\breast_cancimg\\combined_two_cat_images\\train\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_test_path7 = r\"D:\\VSC Workspace\\breast_cancimg\\combined_two_cat_images\\test\\cropped_files\\BENIGN\"\n",
    "malignant_test_path7 = r\"D:\\VSC Workspace\\breast_cancimg\\combined_two_cat_images\\test\\cropped_files\\MALIGNANT\"\n",
    "\n",
    "benign_train7 = load_images(benign_train_path7, DIMENSION)\n",
    "malignant_train7 = load_images(malignant_train_path7, DIMENSION)\n",
    "\n",
    "benign_test7 = load_images(benign_test_path7, DIMENSION)\n",
    "malignant_test7 = load_images(malignant_test_path7, DIMENSION)\n",
    "\n",
    "\n",
    "X_train7 = benign_train7 + malignant_train7\n",
    "X_test7 = benign_test7 + malignant_test7\n",
    "\n",
    "X_train7 = np.array(X_train7)\n",
    "X_train7 = X_train7 / 255.0\n",
    "\n",
    "X_test7 = np.array(X_test7)\n",
    "X_test7 = X_test7 / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Image files, 2 Categories</b>\n",
    "\n",
    "model2 = train_network(X_train2, X_test2, DIMENSION, train_path2, test_path2, 2, \"sigmoid\", \"sparse_categorical_crossentropy\")\n",
    "\n",
    "\n",
    "<b>Image files, 3 Categories</b>\n",
    "\n",
    "model3 = train_network(X_train3, X_test3, DIMENSION, train_path3, test_path3, 3, \"softmax\", \"sparse_categorical_crossentropy\")\n",
    "\n",
    "\n",
    "<b>Cropped files, 3 Categories</b>\n",
    "\n",
    "model4 = train_network(X_train4, X_test4, DIMENSION, train_path4, test_path4, 3, \"softmax\", \"sparse_categorical_crossentropy\")\n",
    "\n",
    "\n",
    "<b>Cropped files, 2 Categories</b>\n",
    "\n",
    "model5 = train_network(X_train5, X_test5, DIMENSION, train_path5, test_path5, 2, \"sigmoid\", \"sparse_categorical_crossentropy\")\n",
    "\n",
    "\n",
    "<b>Cropped files, 3 Categories, combined dataset</b>\n",
    "\n",
    "model6 = train_network(X_train6, X_test6, DIMENSION, train_path6, test_path6, 3, \"relu\")\n",
    "\n",
    "\n",
    "<b>Cropped files, 2 Categories, combined dataset</b>\n",
    "\n",
    "model7 = train_network(X_train7, X_test7, DIMENSION, train_path7, test_path7, 2, \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = train_network(X_train7, X_test7, DIMENSION, train_path7, test_path7, 2, \"relu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
